{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/quhaowen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from joblib import dump, load\n",
    "\n",
    "# Download and set up stopwords\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = set(stopwords.words('english'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T01:39:04.013151Z",
     "end_time": "2024-04-24T01:39:13.377386Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "def preprocess_text(text, stopwords=STOPWORDS):\n",
    "    # Ensure the text is of string type\n",
    "    text = str(text)\n",
    "    # Remove non-alphabetical characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    # Remove stopwords\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "    text = ' '.join(filtered_words)\n",
    "    return text\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T01:39:16.756443Z",
     "end_time": "2024-04-24T01:39:16.766555Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "dev_df = pd.read_csv('dev.csv')\n",
    "\n",
    "# text preprocessing\n",
    "train_df['Processed_Claim'] = train_df['Claim'].apply(preprocess_text)\n",
    "train_df['Processed_Evidence'] = train_df['Evidence'].apply(preprocess_text)\n",
    "dev_df['Processed_Claim'] = dev_df['Claim'].apply(preprocess_text)\n",
    "dev_df['Processed_Evidence'] = dev_df['Evidence'].apply(preprocess_text)\n",
    "\n",
    "# Combine processed text\n",
    "train_df['Text'] = train_df['Processed_Claim'] + \" \" + train_df['Processed_Evidence']\n",
    "dev_df['Text'] = dev_df['Processed_Claim'] + \" \" + dev_df['Processed_Evidence']\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T01:40:04.300999Z",
     "end_time": "2024-04-24T01:40:04.917509Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 3), max_df=0.75, min_df=5)\n",
    "\n",
    "# Vectorize the text\n",
    "X_train = tfidf.fit_transform(train_df['Text']).toarray()\n",
    "y_train = train_df['label'].values\n",
    "X_dev = tfidf.transform(dev_df['Text']).toarray()\n",
    "y_dev = dev_df['label'].values\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T01:43:23.326842Z",
     "end_time": "2024-04-24T01:43:28.181197Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      3484\n",
      "           1       0.65      0.56      0.61      1257\n",
      "\n",
      "    accuracy                           0.80      4741\n",
      "   macro avg       0.75      0.73      0.74      4741\n",
      "weighted avg       0.80      0.80      0.80      4741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the training set and test set\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# train the model\n",
    "class_weights ='balanced'\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, class_weight=class_weights, random_state=42)\n",
    "rf_classifier.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Save the model to a file\n",
    "dump(rf_classifier, 'rf_classifier.joblib')\n",
    "\n",
    "# Predict and evaluate on the development set\n",
    "predictions = rf_classifier.predict(X_test_split)\n",
    "print(classification_report(y_test_split, predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T01:43:29.012252Z",
     "end_time": "2024-04-24T01:45:35.632724Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Load the model\n",
    "rf_classifier = load('rf_classifier.joblib')\n",
    "\n",
    "# Save predictions for dev\n",
    "dev_predictions = rf_classifier.predict(X_dev)\n",
    "dev_df['prediction'] = dev_predictions\n",
    "dev_df[['prediction']].to_csv('dev_predictions.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T01:46:12.382847Z",
     "end_time": "2024-04-24T01:46:13.332067Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Load the model\n",
    "rf_classifier = load('rf_classifier.joblib')\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# text preprocessing\n",
    "test_df['Processed_Claim'] = test_df['Claim'].apply(preprocess_text)\n",
    "test_df['Processed_Evidence'] = test_df['Evidence'].apply(preprocess_text)\n",
    "test_df['Text'] = test_df['Processed_Claim'] + \" \" + test_df['Processed_Evidence']\n",
    "\n",
    "# Vectorize the text\n",
    "X_test = tfidf.transform(test_df['Text']).toarray()\n",
    "\n",
    "# Generate predictions\n",
    "test_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "test_df['prediction'] = test_predictions\n",
    "test_df[['prediction']].to_csv('Group_33_A.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T01:46:14.067398Z",
     "end_time": "2024-04-24T01:46:15.466293Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
